{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# emoji prediciton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   tweet  emoji_class emoji  \\\n",
       "0      Lmao. My #Bitmoji is so perfect. Looks and act...            1     üòÇ   \n",
       "1      I like to call this the #tandem because we dec...            0     ‚ù§   \n",
       "2      Crab dip French toast! Yum! I Miss Shirley's! ...            0     ‚ù§   \n",
       "3      Happy Thanksgiving from my family to yours! Ô∏è ...            0     ‚ù§   \n",
       "4          #familynight Ô∏è @ Soho House West Hollywood \\n            0     ‚ù§   \n",
       "...                                                  ...          ...   ...   \n",
       "10652  Overshine by the sunlight Ô∏è - Golden gate brid...            6     ‚òÄ   \n",
       "10653  Those one handed interception drills coming in...            3     üî•   \n",
       "10654  Can I get a for this good looking group? We're...            0     ‚ù§   \n",
       "10655  w/ @user : @user with the shots @ Manhattan, N...            2     üì∏   \n",
       "10656  Obligatory Wedding Kiss Pic with @user Ô∏èqnhamp...            0     ‚ù§   \n",
       "\n",
       "      predicted_class  \n",
       "0                None  \n",
       "1                None  \n",
       "2                None  \n",
       "3                None  \n",
       "4                None  \n",
       "...               ...  \n",
       "10652            None  \n",
       "10653            None  \n",
       "10654            None  \n",
       "10655            None  \n",
       "10656            None  \n",
       "\n",
       "[10657 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>emoji_class</th>\n      <th>emoji</th>\n      <th>predicted_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Lmao. My #Bitmoji is so perfect. Looks and act...</td>\n      <td>1</td>\n      <td>üòÇ</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I like to call this the #tandem because we dec...</td>\n      <td>0</td>\n      <td>‚ù§</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Crab dip French toast! Yum! I Miss Shirley's! ...</td>\n      <td>0</td>\n      <td>‚ù§</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Happy Thanksgiving from my family to yours! Ô∏è ...</td>\n      <td>0</td>\n      <td>‚ù§</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#familynight Ô∏è @ Soho House West Hollywood \\n</td>\n      <td>0</td>\n      <td>‚ù§</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10652</th>\n      <td>Overshine by the sunlight Ô∏è - Golden gate brid...</td>\n      <td>6</td>\n      <td>‚òÄ</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>10653</th>\n      <td>Those one handed interception drills coming in...</td>\n      <td>3</td>\n      <td>üî•</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>10654</th>\n      <td>Can I get a for this good looking group? We're...</td>\n      <td>0</td>\n      <td>‚ù§</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>10655</th>\n      <td>w/ @user : @user with the shots @ Manhattan, N...</td>\n      <td>2</td>\n      <td>üì∏</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>10656</th>\n      <td>Obligatory Wedding Kiss Pic with @user Ô∏èqnhamp...</td>\n      <td>0</td>\n      <td>‚ù§</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>10657 rows √ó 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
     "execution_count": 6
    }
   ],
   "source": [
    "#import data from csv file for further processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_pickle('emoji_train.pkl')\n",
    "test = pd.read_pickle('emoji_test.pkl')\n",
    "\n",
    "#df.head()\n",
    "#df.tail()\n",
    "#df.columns\n",
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "train\n",
    "test"
   ]
  },
  {
   "source": [
    "## Inspect DataSet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        emoji_class\n",
       "count  42627.000000\n",
       "mean       1.625402\n",
       "std        1.809426\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        3.000000\n",
       "max        6.000000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emoji_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>42627.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.625402</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.809426</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>6.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
     "execution_count": 7
    }
   ],
   "source": [
    "# inspect data here\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        emoji_class\n",
       "count  10657.000000\n",
       "mean       1.625223\n",
       "std        1.809352\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        3.000000\n",
       "max        6.000000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emoji_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10657.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.625223</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.809352</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>6.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
     "execution_count": 8
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 5
     "execution_count": 9
    }
   ],
   "source": [
    "np.unique(train['emoji_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 6
     "execution_count": 10
    }
   ],
   "source": [
    "np.unique(test['emoji_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['tweet', 'emoji_class', 'emoji', 'predicted_class']\n['tweet', 'emoji_class', 'emoji', 'predicted_class']\n"
     ]
    }
   ],
   "source": [
    "print(list(train.columns.values))\n",
    "print(list(test.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0        1\n1        0\n2        0\n3        0\n4        0\n        ..\n10652    6\n10653    3\n10654    0\n10655    2\n10656    0\nName: emoji_class, Length: 10657, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_X = train[\"tweet\"]\n",
    "test_X = test[\"tweet\"]\n",
    "train_y = train[\"emoji_class\"]\n",
    "test_y = test[\"emoji_class\"]\n",
    "\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['10', '11', '12', '16', '17', '1st', '20', '2016', '2017', '2018', '30', '4th', '4th july', 'adventure', 'ago', 'ain', 'air', 'airport', 'amazing', 'america', 'american', 'amp', 'amp user', 'angeles', 'angeles california', 'anniversary', 'arena', 'arizona', 'art', 'artist', 'arts', 'ass', 'atlanta', 'austin', 'available', 'away', 'awesome', 'babe', 'baby', 'bad', 'bar', 'bay', 'bday', 'beach', 'beach california', 'bear', 'beat', 'beautiful', 'beauty', 'beer', 'believe', 'best', 'best friend', 'better', 'beverly', 'beverly hills', 'big', 'bio', 'birthday', 'black', 'blessed', 'blue', 'boston', 'bowl', 'boy', 'boys', 'breakfast', 'bridge', 'bring', 'bro', 'brooklyn', 'brother', 'brunch', 'ca', 'cafe', 'cali', 'california', 'came', 'camp', 'canyon', 'carolina', 'casino', 'cause', 'celebrate', 'celebrating', 'center', 'central', 'check', 'chicago', 'christmas', 'christmas eve', 'christmas tree', 'christmastree', 'church', 'city', 'class', 'club', 'coast', 'coffee', 'cold', 'college', 'color', 'colorado', 'come', 'comes', 'coming', 'community', 'company', 'concert', 'cool', 'couldn', 'country', 'county', 'crazy', 'credit', 'creek', 'crew', 'cute', 'dad', 'dallas', 'damn', 'dance', 'date', 'day', 'days', 'december', 'definitely', 'del', 'desert', 'did', 'didn', 'diego', 'diego california', 'dinner', 'disney', 'disneyland', 'district', 'dj', 'does', 'doesn', 'dog', 'doing', 'don', 'dope', 'downtown', 'downtown los', 'dress', 'drinking', 'drive', 'early', 'east', 'eat', 'el', 'em', 'en', 'end', 'enjoy', 'enjoying', 'eve', 'event', 'excited', 'experience', 'eyes', 'face', 'fair', 'fall', 'falls', 'fam', 'family', 'farm', 'fashion', 'favorite', 'feel', 'feeling', 'feels', 'festival', 'field', 'finally', 'fitness', 'florida', 'follow', 'food', 'forever', 'forget', 'fort', 'francisco', 'francisco california', 'free', 'fresh', 'friday', 'friend', 'friends', 'ft', 'fun', 'funny', 'game', 'garden', 'gate', 'gate bridge', 'georgia', 'get_repost', 'getting', 'gift', 'girl', 'girls', 'glad', 'god', 'going', 'golden', 'golden gate', 'golf', 'gonna', 'good', 'good morning', 'gorgeous', 'got', 'gotta', 'grand', 'grateful', 'great', 'green', 'grill', 'grove', 'guess', 'guy', 'guys', 'gym', 'haha', 'hair', 'half', 'hall', 'halloween', 'hanging', 'happiness', 'happy', 'happy 4th', 'happy birthday', 'happy holidays', 'happy thanksgiving', 'hard', 'having', 'head', 'heart', 'heat', 'hello', 'help', 'hey', 'high', 'high school', 'hiking', 'hill', 'hills', 'hit', 'holiday', 'holidays', 'hollywood', 'home', 'hope', 'hot', 'hotel', 'house', 'houston', 'huntington', 'ice', 'illinois', 'international', 'international airport', 'island', 'jersey', 'job', 'join', 'july', 'just', 'kid', 'kids', 'know', 'la', 'ladies', 'lady', 'lake', 'las', 'las vegas', 'lasvegas', 'late', 'laugh', 'left', 'let', 'life', 'light', 'lights', 'like', 'lil', 'link', 'link bio', 'lit', 'little', 'live', 'll', 'lmao', 'lol', 'long', 'long beach', 'look', 'looking', 'looks', 'los', 'los angeles', 'losangeles', 'lost', 'lot', 'lounge', 'love', 'love love', 'love user', 'loved', 'lovely', 'loves', 'loving', 'lucky', 'lunch', 'magic', 'make', 'makes', 'makeup', 'making', 'malibu', 'mama', 'man', 'manhattan', 'market', 'meet', 'memories', 'merica', 'merry', 'merry christmas', 'merrychristmas', 'miami', 'michigan', 'mind', 'miss', 'missed', 'missing', 'mission', 'model', 'mom', 'moment', 'monday', 'monica', 'month', 'morning', 'mother', 'mountain', 'mr', 'museum', 'music', 'nashville', 'national', 'national park', 'nature', 'need', 'needed', 'nevada', 'new', 'new jersey', 'new year', 'new york', 'newport', 'newyork', 'nice', 'night', 'night user', 'nights', 'nofilter', 'north', 'ny', 'nyc', 'oakland', 'ocean', 'oh', 'ohio', 'old', 'ontario', 'open', 'oregon', 'orlando', 'palm', 'park', 'party', 'people', 'perfect', 'person', 'photo', 'photography', 'photos', 'photoshoot', 'pic', 'pics', 'picture', 'pictures', 'pier', 'pizza', 'place', 'play', 'playing', 'point', 'portland', 'post', 'pretty', 'proud', 'queen', 'ready', 'real', 'really', 'red', 'remember', 'repost', 'repost user', 'resort', 'restaurant', 'ride', 'right', 'river', 'road', 'rock', 'room', 'run', 'sacramento', 'said', 'san', 'san diego', 'san francisco', 'sandiego', 'sanfrancisco', 'santa', 'santa monica', 'saturday', 'saw', 'say', 'school', 'sea', 'season', 'seattle', 'seattle washington', 'seeing', 'selfie', 'set', 'sf', 'shit', 'shoot', 'shooting', 'shop', 'shopping', 'shot', 'sister', 'sisters', 'sky', 'smile', 'snapchat', 'snow', 'son', 'song', 'soon', 'soul', 'south', 'spa', 'special', 'spend', 'spot', 'springs', 'squad', 'square', 'st', 'stadium', 'start', 'state', 'state university', 'states', 'stay', 'stop', 'store', 'street', 'strip', 'studio', 'studios', 'style', 'summer', 'sun', 'sunday', 'sunny', 'sunset', 'sunshine', 'super', 'support', 'sure', 'sweet', 'tag', 'taking', 'tbt', 'team', 'tell', 'tennessee', 'texas', 'thank', 'thank user', 'thankful', 'thanks', 'thanksgiving', 'theatre', 'thing', 'things', 'think', 'tho', 'thought', 'throwback', 'thursday', 'time', 'times', 'today', 'tomorrow', 'tonight', 'took', 'toronto', 'tour', 'town', 'travel', 'tree', 'trip', 'true', 'try', 'trying', 'tuesday', 'union', 'united', 'united states', 'universal', 'university', 'usa', 'use', 'user', 'user amp', 'user los', 'user new', 'user user', 'vacation', 'valley', 've', 'vegas', 'vegas nevada', 'venice', 'venice beach', 'vibes', 'video', 'view', 'village', 'virginia', 'visit', 'wait', 'waiting', 'walk', 'wanna', 'want', 'wanted', 'warm', 'washington', 'watch', 'watching', 'water', 'way', 'weather', 'wedding', 'wednesday', 'week', 'weekend', 'welcome', 'went', 'west', 'white', 'wild', 'win', 'wine', 'winter', 'wish', 'won', 'wonderful', 'work', 'working', 'workout', 'world', 'worth', 'xmas', 'ya', 'year', 'years', 'yes', 'yesterday', 'york', 'york new', 'young', 'youtube', 'zoo']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Learn the vocabulary dictionary and return term-document matrix\n",
    "# Count Vectorizer - Convert a collection of text documents to a matrix of token counts\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", \n",
    "                             preprocessor = None, \n",
    "                             stop_words =  'english', \n",
    "                             max_features = 600, ngram_range=(1,2))\n",
    "word_matrix_train = vectorizer.fit_transform(train_X)\n",
    "\n",
    "word_matrix_test = vectorizer.transform(test_X)\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "#print(word_matrix_train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize term document matrix\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "normalized_train = tfidf_transformer.fit_transform(word_matrix_train)\n",
    "normalized_test = tfidf_transformer.fit_transform(word_matrix_test)"
   ]
  },
  {
   "source": [
    "## Train-Test Split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_train, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 62,
>>>>>>> b0395d68cfbddae852b92aef30ec38451ef90d8e
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/Marcel/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "#neigh.fit(X_train, y_train)\n",
    "#predictions = neigh.predict(X_test)\n",
    "\n",
    "MPLy = MLPClassifier().fit(X_train, y_train)\n",
    "predictions = MPLy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       emoji_class  predictions\n",
       "1557             0            3\n",
       "30385            0            0\n",
       "33335            2            6\n",
       "18623            0            4\n",
       "2982             2            0\n",
       "...            ...          ...\n",
       "2894             0            0\n",
       "19419            0            0\n",
       "28033            1            0\n",
       "36677            0            0\n",
       "19828            4            4\n",
       "\n",
       "[8526 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emoji_class</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1557</th>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>30385</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33335</th>\n      <td>2</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>18623</th>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2982</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2894</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19419</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28033</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36677</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19828</th>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>8526 rows √ó 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "results = pd.DataFrame(y_test)\n",
    "results['predictions'] = predictions\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4029\n4497\n"
     ]
    }
   ],
   "source": [
    "right_pred = 0\n",
    "false_pred = 0\n",
    "\n",
    "for index, row in results.iterrows():\n",
    "    if row['emoji_class'] == row['predictions']:\n",
    "        right_pred += 1\n",
    "    else:\n",
    "        false_pred += 1\n",
    "\n",
    "print(right_pred)\n",
    "print(false_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python373jvsc74a57bd05b09300f1aaa29f91518898d289bfe7c6a13e39f5c39de69ed81889dba9d5a76",
   "display_name": "Python 3.7.3 64-bit ('anaconda3': virtualenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}